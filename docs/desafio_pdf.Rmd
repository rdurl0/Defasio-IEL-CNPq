---
title: "Reposta para o desafio IEL-CNPq"
author: "Raul de Sá Durlo"
date: "16/07/2019"
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage[table]{xcolor}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}

output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    fig_caption: yes
    keep_tex: false
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.height = 3,
                      fig.width = 4)
```

# Introdução

No desenvolvimento de modelos de predição, qual a diferença entre as técnicas de regressão linear e regressão logística? Quais são os indicadores para avaliar a performance de aderência do modelo?

O desafio foi respondido e é apresentado neste relatório dividido nas partes que seguem: 

* Definição de modelos de predição, diferenciando o da inferência estatística.

* Apresentação dos modelos de regressão linear e logísticos definidos.

* Por fim, é discutido os indicadores de performance de aderencia para modelos preditivos.


# Uma breve introdução aos modelos estatísticos

Em um modelo estatístico estamos interessados em obter uma função $f$ que relacione um conjunto de *preditores* ($X$) a alguma *variável de resposta* ($Y$). Os preditores $X = (X_{1}, X_{2}, ..., X_{p})$ também são chamados de *variáveis explicativas*, *variáveis independentes* ou *entrada* (*inputs*).

Podemos descrever relação entre $X$ e $Y$ na forma geral:

$$
Y = f(X) + \epsilon
$$

Onde $f(X)$ representa uma relação sistemática entre o conjunto de preditores $X$ e  a variável de resposta $Y$ e $\epsilon$ é um termo de erro aleatório independente, com média igual a zero.

O gráfico abaixo mostra uma relação bi-variada entre a renda ($Y$) de 30 indivíduos com os seus respectivos anos de estudos ($X$). Cada indivíduo pode ser identificado por um ponto no gráfico e a reta cinza é a representação de um modelo linear simples. A principal característica desse modelo é que a de que minimiza a distância entre os seus valores preditos ($\hat{Y}$) e os valores observados ($Y$) (em vermelho).

```{r}
library(tidyverse)
library(ISLR)

dir <- "C:/Users/rauld/OneDrive/Documentos/[documentos]Raul"
income <- paste0(dir, "/Desafio-IEL-CNPq/data/Income1.csv")

income <- read_csv(income)

fit <- lm(Income ~ Education, data = income)

income$predicted <- predict(fit) # guarda os valores preditos Y_hat
income$residuals <- residuals(fit) # guarda residuos da regressão


# link para o gráfico:
# https://drsimonj.svbtle.com/visualising-residuals
income %>%
  ggplot(aes(Education, Income)) +
  geom_segment(aes(xend = Education, yend = predicted), color = "red") +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "lightgrey") +
  annotate("text", x = 20, y=30,
           label = "Y = - 39.45 + 5.6 * X") +
  geom_point() +
  labs(title = "Renda e anos de estudos") +
  theme_bw()
```

Existem basicamente dois motivos para estimar $f$: a *inferência* e a *predição*.

## Predição

Muitas vezes não podemos obter, de antemão, os valores de $Y$. Por isso, os valores preditos são importantes e estão representados pela reta cinza no gráfico acima. Os valores preditos são estimados por alguma forma funcional assumida para o modelo com as variáveis explicativas (seus erros possuem média zero):

$$\hat{Y} = \hat{f}(X)$$

O foco na predição serve para analisar a precisão de um modelo, ou seja, se os seus valores preditos $\hat{y_{0}}$ acertariam os valores reais $y_{0}$. Entretanto, no geral, $\hat{f}$ não é um estimador perfeito de $f$ e sua diferença (erro) é explicada por fatores *redutíveis* e *irredutíveis*. Podemos decompor esses fatores por meio do quadrado das diferenças entre o valor estimado e a variável de resposta:

$$
E(Y-\hat{Y})^{2} = E[f(X) + \epsilon - \hat{f}(X)]^{2} = [f(X) - \hat{f}(X)]^{2} + Var(\epsilon)
$$

O termo de erro *redutível* corresponde ao termo $[f(X) - \hat{f}(X)]^{2}$ da equação acima e é aquele decorrente da escolha da forma funcional estimada. Assim, o modelo mais preciso é aquele que minimiza essa diferença.

Como $Y$ é função de $\epsilon$ e, por definição, $\epsilon$ não pode ser previsto por $X$. Algum erro sempre será introduzido ao modelo, daí o termo *irredutível*, denotado por $Var(\epsilon)$.


## Inferência

A inferência serve para análise da *maneira* de como os preditores $X_{1}, X_{2}, ..., X_{p}$ afetam a variável de resposta $Y$. Fazemos inferência quando queremos entender a relação entre $X$ e $Y$ ou como $Y$ muda em função de $X_{1}, X_{2}, ..., X_{p}$.

O modelo estatístico utilizado no gráfico acima é um exemplo de um modelo paramétrico linear simples. Paramétrico, pois assume uma forma funcional definida (linear, no caso) e simples, pois possui apenas um preditor.

Um modelo paramétrico normalmente apresenta a desvantagem de ser mais simplificador e inflexível. Aumentar sua complexidade e flexíbilidade implica em aumento no número de parâmetros a serem estimados e, consequentemente, os modelos se tornam mais sensíveis aos erros (*overfitting*). Por outro lado, a simplificação pode ser interessante por questões de interpretabilidade.


```{r}
income %>%
  ggplot(aes(Education, Income)) +
  geom_smooth(aes(color = "Linear"),
              method = "lm",
              se = FALSE) +
  geom_smooth(aes(color = 'spline (df = 4)'),
              method = lm,
              formula = y ~ splines::bs(x, 4),
              se = FALSE) +
  geom_smooth(aes(color = 'Local regression'),
              method = 'loess',
              se = F) +
  geom_point(shape = 1) +
  labs(title = "Renda e anos de estudos",
       subtitle = "") +
  theme_bw()
```

Existem também modelos não paramétricos, onde é feita suposições sobre a forma funcional de $f$ e, portanto, possui a capacidade de se ajustar melhor ao conjunto de dados, com a desvantagem de apresentar mais variabilidade e, consequentemente, ser mais sensível ao termo de erro (*overfitting*).

Novamente, a flexibilidade do modelo deve ser confrontada com a sua intepretabilidade. A figura abaixo representa o tradeoff entre interpretabilidade e flexibilidade de diferentes modelos estatísticos. Em geral, um modelo mais fácil de se interpretar é preferido quando o objetivo é a inferência e um modelo mais flexível é mais recomendado para análises mais preditivas.

\begin{center}
\includegraphics{tradeoff_interpretacao_vs_flexibilidade.png}
\end{center}

Os modelos citados acima podem compor procesos de aprendizagem estatística (*statistical learning*) 

# Regressão linear

# Regressão Logística

# Indicadores de performance e aderência do modelo